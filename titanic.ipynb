{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "training['train_test'] = 1\n",
    "test['train_test'] = 0\n",
    "test['Survived'] = np.NaN\n",
    "all_data = pd.concat([training,test])\n",
    "training_prepared = training.copy()\n",
    "training_prepared = training_prepared.replace({'Sex': { 'male': 0, 'female': 1 }})\n",
    "test_prepared = test.copy().replace({'Sex': { 'male': 0, 'female': 1 }})\n",
    "\n",
    "%matplotlib inline\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prepared.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical values\n",
    "df_num = training_prepared[['Age','SibSp','Parch','Fare','Sex','Pclass']]\n",
    "df_numsv = training_prepared[['Age','SibSp','Parch','Fare','Sex','Pclass','Survived']]\n",
    "numsv = df_numsv.to_numpy()\n",
    "# remove all rows that contain NaN values\n",
    "numsv = numsv[~np.isnan(numsv).any(axis=1)]\n",
    "              \n",
    "fdf = test_prepared[['Fare', 'Sex', 'Pclass']].to_numpy()\n",
    "# use 0s instead of nan (for testing data)\n",
    "fdf = np.nan_to_num(fdf, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_numsv.columns:\n",
    "    plt.hist(df_numsv[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_numsv.corr())\n",
    "sns.heatmap(df_numsv.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen Fare & Sex have a positive correlation with survivability, whilst Pclass is having a negative one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rates across Age, SibSp, Parch, Fare, Sex and Pclass \n",
    "pd.pivot_table(training_prepared, index = 'Survived', values = ['Age','SibSp','Parch','Fare','Sex','Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers fitting and comparison\n",
    "\n",
    "Code is mostly taken from: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=3),\n",
    "    MLPClassifier(alpha=1, max_iter=10000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# Select Fare, Sex, and Pclass as features\n",
    "#   and Survived as target\n",
    "X, y = numsv[:,-4:-1], numsv[:,-1:].T[0]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=.5)\n",
    "\n",
    "mms = []\n",
    "for r in range(X.shape[1]):\n",
    "    mms.append(np.array([X[:, r].min() - .5, X[:, r].max() + .5]))\n",
    "mg = np.meshgrid(*[np.arange(*m, h) for m in mms])\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "ax = plt.subplot(2, (len(classifiers) + 1 + 1) // 2, i, projection='3d')\n",
    "ax.set_title(\"Input data\")\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c=y_train, cmap=cm_bright,\n",
    "           edgecolors='k')\n",
    "# Plot the testing points\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], X_test[:, 2], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "           edgecolors='k')\n",
    "ax.set_xlim(mms[0].min(), mms[0].max())\n",
    "ax.set_ylim(mms[1].min(), mms[1].max())\n",
    "ax.set_zlim(mms[2].min(), mms[2].max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "i += 1\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    ax = plt.subplot(2, (len(classifiers) + 1 + 1) // 2, i, projection='3d')\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f'Classifier: {name};  score: {score}')\n",
    "    matches = (clf.predict(X_test) == y_test)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(np.c_[mms[0].ravel(), mms[1].ravel(), mms[2].ravel()])\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[mms[0].ravel(), mms[1].ravel(), mms[2].ravel()])[:, 1]\n",
    "\n",
    "    # Plot the training points\n",
    "#     ax.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c=y_train, cmap=cm_bright,\n",
    "#                edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], X_test[:, 2], c=matches, cmap='PiYG',\n",
    "               edgecolors='k', alpha=0.5)\n",
    "\n",
    "    ax.set_xlim(mms[0].min(), mms[0].max())\n",
    "    ax.set_ylim(mms[1].min(), mms[1].max())\n",
    "    ax.set_zlim(mms[2].min(), mms[2].max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_zticks(())\n",
    "    ax.set_title(f'{name} ({i - 2})')\n",
    "    ax.text(mms[0].max() - .3, mms[1].min() + .3, mms[2].min() + .3, ('%.3f' % score).lstrip('0'),\n",
    "            size=15, horizontalalignment='right')\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survivors prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select \"Gaussian Process\" classifier\n",
    "gcp = classifiers[3]\n",
    "X = StandardScaler().fit_transform(fdf)\n",
    "final_prediction = gcp.predict(X)\n",
    "ff = np.int32(np.dstack((test['PassengerId'].to_numpy(), final_prediction))[0])\n",
    "final_df = pd.DataFrame(data=ff, columns=['PassengerId', 'Survived'])\n",
    "print(final_df)\n",
    "with open('result.csv', 'w') as f:\n",
    "    f.write(final_df.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
